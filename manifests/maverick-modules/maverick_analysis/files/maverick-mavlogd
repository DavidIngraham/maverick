#!/usr/bin/env python
#
# Script to import ArduPilot logs into influxdb for analysis/display
# https://github.com/fnoop/maverick

import sys, os, shutil, signal, datetime, time, logging, errno, re, ConfigParser, traceback, subprocess, glob
import lockfile, signal, grp
import asyncore, pyinotify
import sqlite3
from grafana_api_client import GrafanaClient
from grafanalib.core import *
from daemon import runner
from pyinotify import WatchManager, AsyncNotifier, ThreadedNotifier, ProcessEvent, IN_CLOSE_WRITE
from pymavlink import DFReader
from pymavlink.DFReader import DFReader, DFReader_binary, DFReader_text
from influxdb import InfluxDBClient, SeriesHelper

class ProcessLog(ProcessEvent):
    def __init__(self, app):
        logger.debug("Starting ProcessLog.__init__")
        logger.debug("App influx_database:" + app.influx_database)
        self.app = app
        
    def process_IN_CLOSE_WRITE(self, event):
        logger.debug("Received IN_CLOSE_WRITE event")
        self.process(event.pathname)
    def process_IN_MOVED_TO(self, event):
        logger.debug("Received IN_MOVED_TO event")
        self.process(event.pathname)

    def process(self, filename):
        logger.info("Processing data from "+filename)
        if filename.endswith('.log'):
            log = DFReader_text(filename, False)
            logger.debug("Text mavlog detected, creating text parser")
        else:
            log = DFReader_binary(filename, False)
            logger.debug("Binary mavlog detected, creating binary parser")
        parameters = {}
        formats = {}
        json_points = []
        counter = 0
        first_timestamp = None
        first_epoch = None
        last_timestamp = None
        last_epoch = None
        while True:
            entry = log.recv_msg()
            if entry is None:
                logger.debug("No more log entries, break from processing loop")
                break
            msgtype = entry.fmt.name
            if msgtype == "PARM":
                parameters[entry.Name] = entry.Value
            elif msgtype == "FMT":
                formats[entry.Name] = {'format': list(entry.Format), 'columns': entry.Columns.split(",")}
            else:
                if msgtype in formats:
                    _fields = {column:getattr(entry, column) for column in formats[msgtype]['columns']}
                    last_timestamp = datetime.datetime.fromtimestamp(entry._timestamp).strftime('%Y-%m-%d %H:%M:%S.%fZ')
                    last_epoch = int(float(entry._timestamp)*1000000000)
                    if not first_timestamp:
                        first_timestamp = last_timestamp
                        first_epoch = last_epoch
                    if msgtype in ["CMD", "ERR", "EV", "MODE", "MSG"]:
                        #if msgtype == "CMD":
                        #    _fields = {"title": "Command", "tags": "command", "text": str(entry)}
                        if msgtype == "ERR":
                            [subsystxt, ecodetxt] = self.error_text(getattr(entry, "Subsys"), getattr(entry, "ECode"))
                            if ecodetxt:
                                _fields = {"title": "Error", "tags": "error", "text": subsystxt+"<br>"+ecodetxt}
                            else:
                                _fields = {"title": "Error", "tags": "error", "text": subsystxt}
                        elif msgtype == "EV":
                            _fields = {"title": "Event", "tags": "event", "text": self.event_text(getattr(entry, "Id"))}
                        elif msgtype == "MODE":
                            _fields = {"title": "Mode Change", "tags": "mode", "text": "Mode: "+self.mode_text(getattr(entry, "Mode"))+"<br>Reason: "+self.modereason_text(getattr(entry, "Rsn"))}
                        elif msgtype == "MSG":
                            _fields = {"title": "Message", "tags": "message", "text": getattr(entry, "Message").rstrip()}
                        json_body = {
                            "database": self.app.influx_database,
                            "time_precision": "ns",
                            "measurement": "events",
                            "tags": {
                                "filename": filename,
                                "event_type": msgtype.lower()
                            },
                            "time": last_epoch,
                            "fields": _fields
                        }
                        json_points.append(json_body)
                        #logger.debug("Mode:"+str(json_body))
                    else:
                        json_body = {
                            "database": self.app.influx_database,
                            "time_precision": "ns",
                            "measurement": "flight_"+msgtype.lower(),
                            "tags": {
                                "filename": filename
                            },
                            "time": last_epoch,
                            "fields": _fields
                        }
                        json_points.append(json_body)
                    counter += 1
            # Batch writes to influxdb, much faster
            if counter > 0 and counter % 1000 == 0:
                # logger.debug(" - Batch sending 1000 points to influxdb:"+str(counter))
                self.app.client.write_points(json_points)
                json_points = [] # Clear out json_points after bulk write
        # Write any remaining points
        self.app.client.write_points(json_points)
        logger.info("Processing complete of "+filename)
        logger.info(str(counter) + " datapoints inserted.  First timestamp is " +str(first_timestamp)+":"+str(first_epoch) + ", Last timestamp is " + str(last_timestamp)+":"+str(last_epoch))
        self.meta_entry(filename, int(first_epoch/1000000000), int(last_epoch/1000000000))
        self.archive_file(filename)
        self.dashboard_links()
    
    def meta_entry(self, filename, start, finish):
        # Work out source
        file = os.path.basename(filename)
        dirs = os.path.split(filename)
        dirfrags = dirs[0].split(os.path.sep)
        filename = dirs[1]
        # Connect to meta db
        conn = sqlite3.connect(self.app.config['meta_database'])
        cursor = conn.cursor()
        # See if entry already exists
        cursor.execute("SELECT id FROM logfiles WHERE filename='"+filename+"'")
        try:
            id_exists = cursor.fetchone()[0]
        except:
            id_exists = None
        if not id_exists:
            cursor.execute('INSERT INTO logfiles (filename, start, finish, source) VALUES (?,?,?,?)', (filename, start, finish, dirfrags[-1].title()))
        else:
            cursor.execute('UPDATE logfiles SET start=?,finish=?,source=? WHERE id=?', (start,finish,dirfrags[-1].title(),id_exists))
        conn.commit()
        conn.close()
        
    def archive_file(self, filename):
        file = os.path.basename(filename)
        dirs = os.path.split(filename)
        dirfrags = dirs[0].split(os.path.sep)
        destfile = os.path.sep.join(["/srv/maverick/data/mavlink/archive",dirfrags[-1],dirs[1]])
        shutil.move(filename, destfile)
        logger.info("Archiving file from " +filename+ " to " +destfile)

    def dashboard_links(self):
        # Retrieve metadata
        logentries = []
        conn = sqlite3.connect(self.app.config['meta_database'])
        cursor = conn.cursor()
        cursor.execute("SELECT filename,start,finish,source FROM logfiles ORDER by datetime(\"finish\") DESC")
        rows = cursor.fetchall()
        for row in rows:
            try:
                fromdt=str(int(float(row[1]))*1000)
                todt=str(int(float(row[2]))*1000)
                logentries.append("<tr><td>"+row[3]+"</td><td>"+row[0]+"</td><td>"+datetime.datetime.fromtimestamp(float(row[1])).strftime('%Y-%m-%d %H:%M:%S')+"</td><td>"+datetime.datetime.fromtimestamp(float(row[2])).strftime('%Y-%m-%d %H:%M:%S')+"</td><td><a href='/dashboard/db/flight-data-analysis?orgId=10&from="+fromdt+"&to="+todt+"'>Flight Data Analysis</a></td><td><a href='/dashboard/db/flight-ekf2-analysis?orgId=10&from="+fromdt+"&to="+todt+"'>EKF2 Analysis</a></td></tr>")
            # If dates are in old format, skip entry
            except:
                pass
        conn.close()
        # Construct the dashboard
        dashboard = {
            "editable": False,
            "hideControls": True,
            "rows": [{"panels": [{
                  "content": "<table><thead><tr><th>Source</th><th>Filename</th><th>Start</th><th>Finish</th><th>Flight Data Link</th><th>EKF Data Link</th></tr></thead><tbody>"+"\n".join(logentries)+"</tbody></table>",
                  "mode": "html",
                  "span": 12,
                  "title": "Flight Logs",
                  "type": "text"
                }],
            "title": "Flight Logs",
            }],
            "schemaVersion": 14,
            "style": "dark",
            "timezone": "browser",
            "version": int(time.time()),
            "title": "Flight Logs Index"
        }
        # Create/update the dashboard in grafana
        grafana = GrafanaClient((self.app.config['grafana_user'], self.app.config['grafana_password']), host="127.0.0.1", port=6790)
        dashreturn = grafana.dashboards.db.create(dashboard=dashboard, overwrite=True)
        logger.debug("Grafana dashboard update:"+str(dashreturn))
        
    def error_text(self,subsys,ecode):
        subsysId = {
            1: "Main",
            2: "Radio",
            3: "Compass",
            4: "Optical Flow",
            5: "Failsafe Radio",
            6: "Failsafe Battery",
            7: "Failsafe GPS",
            8: "Failsafe GCS",
            9: "Failsafe Fence",
            10: "Flight Mode",
            11: "GPS",
            12: "Crash Check",
            13: "Flip",
            14: "Autotune",
            15: "Parachute",
            16: "EKF Check",
            17: "Failsafe EKF INAV",
            18: "Barometer",
            19: "CPU",
            20: "Failsafe ADSB",
            21: "Terrain",
            22: "Navigation",
            23: "Failsafe Terrain",
            24: "EKF Primary"
        }
        ecodes = {}
        if subsys == 1:
            ecodes = {
                1: "INS Delay"
            }
        elif subsys == 2:
            ecodes = {
                2: "Radio Late Frame"
            }
        elif subsys == 3:
            ecodes = {
                2: "Compass Failed to Read"
            }
        elif subsys == 5 or subsys == 6 or subsys == 7:
            ecodes = {
                0: "Failsafe Resolved",
                1: "Failsafe Occurred"
            }
        elif subsys == 12:
            ecodes = {
                1: "Crash",
                2: "Loss of Control"
            }
        elif subsys == 13:
            ecodes = {
                2: "Flip Abandoned"
            }
        elif subsys == 15:
            ecodes = {
                2: "Parachute Too Low",
                3: "Parachute Landed"
            }
        elif subsys == 16:
            ecodes = {
                2: "Bad Variance",
                0: "Variance Cleared"
            }
        elif subsys == 18:
            ecodes = {
                2: "Barometer Glitch"
            }
        elif subsys == 21:
            ecodes = {
                2: "Missing Terrain Data"
            }
        elif subsys == 22:
            ecodes = {
                2: "Failed to Set Destination",
                3: "Restarted RTL",
                4: "Failed Circle Init",
                5: "Destination Outside Fence"
            }
        else:
            ecodes = {
                0: "Error Resolved",
                1: "Failed to Initialise",
                4: "Unhealthy"
            }
        
        try:
            if subsys == 10:
                return [subsysId[subsys], "Attempting to change to flight mode: <b>"+self.mode_text(ecode)+"</b>"]
            else:
                return [subsysId[subsys], ecodes[ecode]]
        except:
            return [subsysId[subsys], None]

    def modereason_text(self,id):
        idText = {
            0: "Reason Unknown",
            1: "TX Command",
            2: "GCS Command",
            3: "Radio Failsafe",
            4: "Battery Failsafe",
            5: "GCS Failsafe",
            6: "EKF Failsafe",
            7: "GPS Glitch",
            8: "Mission End",
            9: "Throttle Land Escape",
            10: "Fence Breach",
            11: "Terrain Failsafe",
            12: "Brake Timeout",
            13: "Flip Complete",
            14: "Avoidance",
            15: "Avoidance Recovery",
            16: "Throw Complete"
        }
        try:
            return idText[id]
        except:
            return "Mode Reason ID not recognised"

    def mode_text(self,id):
        idText = {
            0: "Stabilize",
            1: "Acro",
            2: "Altitude Hold",
            3: "Auto",
            4: "Guided",
            5: "Loiter",
            6: "Return To Launch",
            7: "Circle",
            9: "Land",
            11: "Drift",
            13: "Sport",
            14: "Flip",
            15: "Autotune",
            16: "Position Hold",
            17: "Brake",
            18: "Throw",
            19: "Avoid ADSB",
            20: "Guided No GPS"
        }
        try:
            return idText[id]
        except:
            return "Mode ID not recognised"

    def event_text(self, id):
        idText = {
            7: "AutoPilot State",
            8: "System Time Set",
            9: "Init Simple Bearing",
            10: "Armed",
            11: "Disarmed",
            15: "Auto Armed",
            17: "Land Complete (Maybe)",
            18: "Land Complete",
            19: "Lost GPS",
            21: "Flip Start",
            22: "Flip End",
            25: "Set Home",
            26: "Simple On",
            27: "Simple Off",
            28: "Not Landed",
            29: "Super Simple On",
            30: "Autotune Initialised",
            31: "Autotune Off",
            32: "Autotune Restart",
            33: "Autotune Success",
            34: "Autotune Failed",
            35: "Autotune Reached Limit",
            36: "Autotune Pilot Testing",
            37: "Autotune Saved Gains",
            38: "Save Trim",
            39: "Save/Add Waypoint",
            41: "Fence Enable",
            42: "Fence Disable",
            43: "Acro Trainer Disabled",
            44: "Acro Trainer Leveling",
            45: "Acro Trainer Limited",
            46: "Gripper Grab",
            47: "Gripper Release",
            49: "Parachute Disabled",
            50: "Parachute Enabled",
            51: "Parachute Released",
            52: "Landing Gear Deployed",
            53: "Landing Gear Retracted",
            54: "Motors Emergency Stopped",
            55: "Motors Emergency Stop Cleared",
            56: "Motors Interlock Disabled",
            57: "Motors Interlock Enabled",
            58: "Rotor Runup Complete",
            59: "Rotor Speed Below Critical",
            60: "EKF Altitude Reset",
            61: "Land Cancelled by Pilot",
            62: "EKF Yaw Reset",
            63: "Avoidance ADSB Enable",
            64: "Avoidance ADSB Disable",
            65: "Avoidance Proximity Enable",
            66: "Avoidance Proximity Disable",
            67: "GPS Primary Changed"
        }
        try:
            return idText[id]
        except:
            return "Event ID not recognised"

### Main App Class
class App():
    def __init__(self):
        self.stdin_path = '/dev/null'
        self.stdout_path = '/srv/maverick/var/log/analysis/maverick-mavlogd.daemon.log'
        self.stderr_path = '/srv/maverick/var/log/analysis/maverick-mavlogd.daemon.log'
        self.pidfile_path = '/srv/maverick/var/run/maverick-mavlogd.pid'
        self.pidfile_timeout = 5

    def run(self):
        logger.info("")
        logger.info("--------------------------------")
        logger.info("Starting maverick-mavlogd daemon")
        # Get config
        self.config = self.config_parse("/srv/maverick/data/config/analysis/maverick-mavlogd.conf")
        self.influx_database = self.config['influx_database']
        self.client = InfluxDBClient(self.config['influx_server'], self.config['influx_port'], self.config['influx_user'], self.config['influx_password'], self.influx_database)
        if not self.client:
            logger.critical("Error connecting to InfluxDB")
            sys.exit(1)
        self.client.create_database(self.influx_database)
        self.logdirs = self.config['logdirs']
        self.watch_dirs()
        self.metadb(self.config['meta_database'])
        # Loop and wait for files
        asyncore.loop()

    def watch_dirs(self):
    	watch_manager = WatchManager()
        mask = pyinotify.IN_CLOSE_WRITE | pyinotify.IN_MOVED_TO | pyinotify.IN_MOVED_FROM
        notifier = pyinotify.AsyncNotifier(watch_manager, ProcessLog(self))
    	for logdir in self.logdirs.split(","):
    		logger.info("Watching directory: "+str(logdir))
    		watch_manager.add_watch(logdir, mask)

    def config_parse(self, path):
        Config = ConfigParser.SafeConfigParser()
        options = {}
        try:
            Config.read(path)
            for item in Config.options("mavlogd"):
                options[item] = Config.get("mavlogd", item)
            logger.info("Config read from " + str(path))
        except:
            logger.critical("Error reading config file: " + str(path))
            sys.exit(1)
        return options

    def metadb(self, path):
        conn = sqlite3.connect(path)
        cursor = conn.cursor()
        # Create logfiles table if it doesn't exist
        cursor.execute('CREATE TABLE IF NOT EXISTS logfiles (id INTEGER PRIMARY KEY AUTOINCREMENT, filename TEXT, start TEXT, finish TEXT, source TEXT)')
        # Add source column if it doesn't exist
        try:
            cursor.execute("ALTER TABLE logfiles ADD COLUMN source TEXT default null");
        except:
            pass
        conn.commit()
        conn.close()

if __name__ == "__main__":
    # Setup logging
    logger = logging.getLogger("DaemonLog")
    logger.setLevel(logging.DEBUG)
    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    handler = logging.FileHandler("/srv/maverick/var/log/analysis/maverick-mavlogd.log")
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    # Create app instance and daemonize
    app = App()
    daemon_runner = runner.DaemonRunner(app)
    daemon_runner.daemon_context.files_preserve=[handler.stream]
    try:
        daemon_runner.do_action()
    except runner.DaemonRunnerStopFailureError as Error:
        if Error:
            print "Error: " + str(Error)
        print " - mavlogd not running, cannot stop"
        # If stop action, just ignore the error and exit
        if daemon_runner.action == "stop":
            sys.exit(0)
        elif daemon_runner.action == "restart":
            print " - starting mavlogd"
            daemon_runner.action = "start"
            daemon_runner.do_action()
